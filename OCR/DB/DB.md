# DB Differentiable Binarization
## 背景
DB是华科白翔老师团队在AAAI2020发表的文章，基于像素分割的方式进行文字检测，相比较于之前的PixelLink、PSE等检测网络，能够在提升推理性能的同时保证较好的检测效果。目前为止在工业界中也得到了较多的应用，例如微信中提取图片文字、百度PaddleOCR等。  
原文：Real-time Scene Text Detection with Differentiable Binarization  
github代码仓地址：https://github.com/MhLiao/DB.git

## 核心思想
之前的网络以分割的方式做文本检测时，都是对像素点分类为文本和非文本，具体是将文本图像作为网络输入，经过网络预测之后得到每个像素点被分类为文本的概率值，对概率设置一个阈值t，大于t的视为文本像素，小于t的视为非文本像素，然后再进行后处理，得到文本行。  
DB这篇文章的核心就是将阈值t作为一个可训练的map，在训练时对图像的t值进行预测，测试时就不需要人工找到最优阈值，而是使用预测的自适应阈值，从而提升文本检测的效果。  
作者在具体的训练实践中发现，将阈值图加入网络中学习对网络本身的文本像素预测也有正向效果，使得后续使用时即使还是采用固定阈值分割（这样能够简化网络推理过程），也能得到更好的结果。

## 网络结构
![sparkles](Architecture_of_DB.jpg)  
输入图像经过backbone网络提取特征金字塔，所有的特征金字塔经过上采样到相同尺度，concat得到特征F，F再进行训练，预测概率图$P$和阈值图$T$，通过$P$和$T$计算得到近似二值图$\widehat{B}$，最后通过$\widehat{B}$经过后处理得到文本边界框  
$$\widehat{B}_{i,j}=\frac{1}{1+e^{-k(P_{i,j}-T_{i,j})}}$$
$k$根据经验设为50，近似二值图与一般的二值化公式效果类似：
$$B_{i,j}=
\begin{cases}
1　if\ P_{i,j}>=t,\\
0　otherwise.
\end{cases}$$
但是由于$\widehat{B}$可微，因此可以在网络的训练过程中进行优化。

## 标签
对于正常的文本框标签$G$，向内收缩得到文本框$G_s$，作为概率图的标签；  
向外膨胀得到文本框$G_d$，计算$G_s$和$G_d$之间像素到原始文本框$G$之间的最短距离，作为阈值图标签。（这里最短距离可以理解为像素点到原始文本框最近的边的距离）  
收缩和膨胀的偏置为：
$$D=\frac{A(1-r^2)}{L}$$
$r$设为0.4（经验值）。$L$是文本框周长，$A$是文本框面积

## 损失函数
$$L=L_s + \alpha \times L_b+\beta \times L_t$$  
其中$L_s$是概率图$P$的损失，$L_b$是近似二值图$\widehat{B}$的损失，文章中$\alpha$和$\beta$分别设为1和10。$L_s$和$L_b$使用二值交叉熵损失：  
$$L_s=L_b=\sum_{i\in S_l}y_i\log x_i+(1-y_i)\log (1-x_i)$$  
为了平衡正负样本，对负样本进行采样，$S_l$是正负样本比例为1:3的样本集。  
其中阈值损失$L_t$是膨胀文本框$G_d$内预测值和标签值的$L1$距离和：  
$$L_t=\sum_{i \in R_d}|y_i^*-x_i^*|$$  
其中$R_d$是在膨胀文本框内的像素indexs，$y^*$是对应的阈值图标签。  


## 推理
文中在推理时，测试使用预测的概率图直接进行二值化和使用近似二值图生成的文本框结果几乎一样，因此可以直接使用概率图，而在推理时去除预测阈值图。  
生成文本框的过程：
- 概率图首先以0.2（文章中）为阈值进行二值化，得到二值图，在代码中设置的阈值为0.3
- 通过二值图得到连接区域（收缩文本区域）
- 收缩文本区域进行膨胀，偏置为$D'$:
  $$D'=\frac{A' \times r'}{L'}$$
  $r'$设为1.5（经验值），$A'$为收缩多边形面积，$L'$为收缩多边形周长。


## 代码相关
### 训练
作者在github仓中的代码有较多的配置yaml文件，容易看晕，如果要使用源码训练自己的数据，需要按照experinments/seg_detector/ 文件夹进行配置文件编写，自行准备base_xxx.yaml和xxx_deform_thre.yaml文件，四点框训练可参考ic15相关，多点框训练可参考totaltext相关。  
训练是将图像数据路径生成list，写入base_xxx.yaml，相关的读取代码位于data/image_dataset.py，需要根据自己的数据存放方式进行对应修改  
其他问题：作者在读取标签文件的中对TD500数据进行了特殊处理，需要注意自己的数据名是否含有TD而被影响  
训练的初始学习率直接使用命令参数--lr无法生效，还是默认的0.007，需要在代码training/learning_rate.py中进行修改，但中断训练后设置resume模型和起始epoch、iter学习率也可以相应正常生效

### loss
实际在训练代码中使用的loss与文章中有差异： 
$$loss = dice\_loss + self.l1\_scale * l1\_loss + bce\_loss * self.bce\_scale$$  
dice_loss是计算的二值化图的loss，l1_loss是计算的阈值图的loss，系数10, bce_loss是计算的概率图的loss，系数5  
### 阈值
代码中后处理涉及到另一个thresh参数为box_score平均分值，用于对生成的文本框进行过滤，可根据具体情况进行设置。  
需要注意的是在长文本的预测中由于文本带有弯曲，使得平均分值计算较低（弧形文本四点框包含了许多非文本像素点），解决方式有两种，一种是调节box_thresh参数更小，一种是修改计算box_score的方式，使用二值图得到的contour计算平均分值，而不是使用四点框，可以修改代码中score = self.box_score_fast(pred, points.reshape(-1, 2))为score = self.box_score_fast(pred, contour.reshape(-1, 2))  
### 多点框输出
推理输出多点框时，发现长文本框无法输出，分析发现多点框的生成使用了cv2.approxPolyDP函数，代码中该函数的epsilon取值较大，是的许多长文本取完不足四点，被过滤，可对应修改epsilon参数设置  
